# 延伸和方向

## 10.1 引言

自 2003 年发布 H.264|AVC 的第一个版本依以来，视频编码行业一直在不断发展。视频平台和交付机制的范围不断扩大，人们越来越期望视频内容可以在任何平台上获得，从移动到高清和 3D 显示，通过任何网络，包括广播、互联网、移动等。自 2003 年以来，该标准本身已有所发展。本章总结了该标准最近的扩展，并介绍了 H.264 之后可能出现的情况。

所谓的“专业”或“保真度范围”扩展成为了 H.264 的High Profile，这是一种用于以极高的再现保真度对高清晰度和工作室内容进行编码的工具，如前几章所述。

越来越多的人需要以不同的带宽和显示分辨率对相同的原始内容进行编码，这导致了可伸缩视频编码(SVC)扩展到 H.264，标准化为 H.264 SVC。SVC 以这样的方式支持视频的有效编码，即视频信号的多个版本可以在比特率、空间分辨率和/或时间分辨率或帧速率的范围内解码。通过联合编码多个版本，应该能够以比单独编码和传输每个版本更有效的方式交付它们。

有一种趋势是创建和交付同一视频场景的多个视图。采用合适的显示技术的立体视频给人以三维(3D)图像的印象。场景的多个视图可以为用户提供选择其视点的选项。“自由视点”视频通过合成实际摄像机位置之间的中间视图，有可能提供场景的任何视图。这些“多视图”应用通常需要对多个密切相关的视频信号或视图进行编码。与SVC类似，多视图视频编码（MVC）利用这些视图之间的相关性来提供高效压缩。用于多视点视频编码的工具已经标准化为H.264 MVC。

视频压缩格式的数量不断增加，越来越多的内容被制作并编码成许多不同的、不兼容的压缩格式。可配置视频编码的最新举措解决了有效支持越来越多的压缩格式的问题。MPEG的可重构视频编码（RVC）子组定义了一个视频工具库、一组标准功能单元和视频压缩的构建块。可以通过定义功能单元的子集及其参数和互连来指定特定视频编解码器。这将使得灵活地重新配置视频编解码器以支持多种标准和专有格式称为可能。更进一步，完全可配置视频编码(FCVC)使得使用一组低级基本操作完全定义和实现任意视频编解码以及在视频通信会话期间更改该定义成为可能。这种方法的潜在好处包括能够快速实现任何新的视频编解码算法，并动态调整压缩算法以适应当前视频场景的特征。

H.264 已被证明是一种有用且成本的技术标准，并将继续增加其在视频编码市场中的份额。随着处理器能力的不断发展，标准界正在考虑 H.264/AVC 之后的内容。在撰写本文时(2010年初)，MPEG 和 VCEG 小组正在研究下一代视频编码标准的建议，该标准有望提供比 H.264 更好的性能，可能需要更高的计算成本。

## 10.2 可分级的视频编码基础

### 10.2.1 同播传输

许多视频压缩应用程序面临的一个挑战是在不同的操作点(即不同的质量、空间分辨率和帧速率)交付视频序列的多个版本。这可以通过使用传统视频编解码器(如H.264|AVC)通过独立地编码每个流来实现。这是联播。在典型的场景中(图10.1),需要将单个源视频传输到多个解码器或客户端，每个解码器或客户端具有不同的功能。在该示例中，原始视频剪辑被编码三次以上产生三个独立的AVC流，每个AVC流被发送和解码。同播场景的问题是三个比特流包含大量冗余，因为相同的视频序列以不同的分辨率和/或质量编码在每个比特流中。理论上，通过利用三个流之间的这种冗余，可以利用更小的传输带宽。

### 10.2.2 可伸缩传输

可伸缩视频编码(SVC)尝试交付多个视频序列的编码序列，它通过使用比上述同播场景更低的总体比特率来达到此目的。它通过利用不同版本之间的冗余来实现这一点，即在不同操作点编码额相同序列的不同版本之间的相关性。

如图10.2所示，使用SVC交付相同的三个序列。单个SVC编码器产生三个编码比特流，称为 Layers。最底层或基本层(图中的 Layer 0)是可使用标准单层解码器(例如，H.264 解码器)解码的流，以在可用质量/分辨率操作点中的最低质量/分辨率生成视频序列。一个或多个增强Layer(Layer 1 和 Layer 2)被编码为 SVC 比特流。为了以更高的质量或分辨率解码序列，SVC解码器解码基本层和一个或多个增强层。在该示例中，使用标准 AVC 解码器解码 Layer 0，产生最低质量的输出；使用SVC解码器解码 Layer 0 和 Layer 1产生更高质量的输出，使用SVC解码器解码 Layer0、Layer1和Layer2产生最高质量的输出。SVC 编码过程通过预测来自基本层和较低增强层的连续增强层，利用以不同分辨率或质量编码的序列之间的冗余。通过这种方式，应该能够以较低的贷款成本实现与同播系统(图10.1)相同的显示结果。

可伸缩编码比特流的一般概念是“流的一部分可以以这样的方式被移除，从而产生的子流形成用于某个目标解码器的另一个有效比特流”。考虑到图10.2，可伸缩比特流由编码的 Layer0、Layer1和Layer2流组成。解码所有三个流产生高质量的输出；移除 Layer2并解码Layer0和Layer1， 产生中等质量输出；移除 Layer1和Layer2并仅解码基本层会产生低质量的输出。

### 10.2.3 可伸缩视频编码的应用

可伸缩视频编码已经被提出用于许多应用场景。

**多解码器：** 越来越多地，相同的原始视频内容由多个设备编码、传输和观看，每个设备具有不同的功能。例如，电影预告片流式传输（从具有低比特率网络连接和低分辨率显示器的手持设备，到具有高比特率连接和高清晰度显示器的PC）到客户端。一系列因素可限制特定解码设备的能力，包括连接比特率、屏幕分辨率和处理能力。一个可伸缩的比特流应该能够尽可能有效地支持广泛的解码能力。

**优雅的降级/增强：** 虽然广播电视等一些应用往往具有清晰定义且一致的视频传输信道，但许多其他应用使用的信道在通信会话期间可能会发生较大的变换。例如，基于IP的应用程序(如视频流或internet会议)将经历不同的通道吞吐量，这取决于网络中的流量和拥塞等因素。可伸缩编码提供了一种机制，用于最大化特定解码器在特定时间点的质量。例如，流式服务器传输视频源的基本层和增强层。解码器尝试接收每个可用Layers。如果成功接收到所有 Layers，解码器将以最大可用质量提取序列。如果连接吞吐量下降，则解码器仅通过接收选定的Layers而回落到较低质量的序列。只要成功解码基本层，就可以始终显示基本质量的视频序列。这意味着基础层非常重要，即优先级高于增强层。

**Achieving** 将视频序列存储为可伸缩编码比特流可以使快速解码视频序列的低质量“预览”成为可能。例如，HD 序列被编码为多个可伸缩层。仅提取 Base Layer 会得到一个低质量的版本，该版本可以快速解码和显示，适合作为整个序列的预览。

### 10.2.4 H.264 中的可伸缩视频编码

可伸缩视频编码(SVC)作为H.264/AVC标准最新版本的附录G，并扩展了原始标准的功能。一个软件实现，联合可伸缩视频模型(JSVM)可供下载和实验。H.264 SVC 支持三种主要类型或类别的可伸缩性(如图10.3):

1. **时间可伸缩性：** Base Layer 是以低时间分辨率或低帧速率编码，添加增强层会增加解码序列的帧速率。    
2. **空间可伸缩性：** Base Layer 是以低空间分辨率编码，添加增强层可提高解码序列的空间分辨率。  
3. **质量可伸缩性：** Base Layer 使用高 QP 以低视觉质量编码；添加增强层可提高解码序列的视觉质量。  

### 10.2.5 时间可伸缩性

在以时间可伸缩性编码的序列中，以最低时间分辨率(即，最低帧率)编码Layer 0。当使用 Base Layer 解码时，连续增强层提供逐渐更高的解码帧速率。图10.4显示了编码为三个时间可伸缩性的序列。Layer 0 以帧速率F0进行编码，并由编码帧0，6，12等组成。H.264|AVC解码器可以单独解码 Layer 0。

Layer 1由第3帧、第9帧、第15帧等组成。解码器可以对 Layer 0 和 Layer 1进行解码，以每秒2 * F0 很的速度产生更高速的序列(如图10.5)。Layer 2 由帧1/2/4/5/7/8等组成，解码器解码Layer0,1,2可以以每秒6 * F0帧的速度提供输出序列(图10.5)。

可以使用 H.264|AVC中提供的 P Slice和/或 B Slice 编码工具实现时间可伸缩性。图10.4和图10.5中的示例，使用了第6章(第6.4.7节)中讨论的"分层"或“金字塔”图片组织结构开发的。为完整起见，图10.6显示了该层次结构的预测方向。Base Layer由每 12 Layer 的I slice 和第一组 B slice B6等组成。Layer 1 由第二组 B slice(3/9/15等)组成，这些 slice 是从 base layer 预测的。Layer 2 由 Layer 0 和 Layer 1预测的剩余 B slice 组成。因此，可以独立地解码以下子集：

Layer 0, I0, B6, I12...   
Layer 0 + Layer 1, I0, B3, B6, B9...  
Layer 0 + Layer 1 + Layer 2, I0, B1, B2, B3, ...  

由于 H.264|AVC 的 Main 和 High Profiles 中支持必要的预测工具，即用于参考的 P 或 B 图片，因此无需对核心 H.264|AVC标准进行任何扩展即可实现时间可伸缩性。

### 10.2.6 质量可伸缩性：概述

如图10.7所示，base layer使用特定量化器参数 QP 进行编码，以产生 Layer 0 比特流。考虑单个视频帧 A。在编码器处，该编码帧从 Base Layer 解码并重构(帧A'0)。帧A以较低的 QP 重新编码，因此具有较高的质量，解码帧A'0可用作预测参考，以产生增强层比特流 Layer 1。注意，A'0 通常是一个非常有效的预测参考，因此除了压缩引起的失真外，它与帧A 相同。注意，“常用”预测源，即解码图片缓冲器中先前编码的帧，也可用于每个宏块的预测。

Base Layer解码器仅解码帧 A0。增强层解码器需要解码的A(预测参考)来重构更高质量的帧A1。

可以重复该过程以形成 Layer0,1,2的级联，每一层(a)使用来自该 Layer 的重构帧作为预测参考，(b)使用逐渐降低的 QP。注意，SVC提供的工具使得能够在不完全解码 Base Layer信息(约束层间预测)的情况下重构增强层。

### 10.2.7 空间可伸缩性：概述

在空间可伸缩性的情况下(图10.8),base layer 具有最低分辨率，连续增强层可以解码以提供更高分辨率的解码帧或场。

在编码器处，对输入视频帧 A 进行下采样，以产生低分辨率版本 A'。帧 A' 被编码以产生 Layer0，并且可以被解码以给出低分辨率输出帧A0。编码器重构A0并对其进行上采样，以生成与原始(A)具有相同有效分辨率的参考帧。该参考帧用作预测参考，使得编码器能够产生增强 Layer1。上采样 A0 通常是帧 A 的良好预测参考，因为它是相同的帧，由于下采样、编码和上采样而产生失真。

增强层解码器向上采样A0并使用其重构解码的增强帧 A1。与质量可伸缩性一样，可以重复此构成，以提供层0、1、2等的级联。最高分辨率层与原始序列具有相同的分辨率；较低的层以逐渐减小的分辨率进行编码。

### 10.2.8 空间可伸缩性详解

如上所述，使用前面章节中描述的常用 H.264|AVC 工具对空间可伸缩性比特流的 Base Layer 进行编码。根据来自较低层的预测的类型，在增强层中编码宏块需要许多改变。H.264 SVC 超越了对较低层进行上采样的基本方法(第10.2.7节)，并提供了几种新的预测模式，以提高空间可伸缩压缩的编码性能。

在增强层编码器中(例如图10.8中的编码器1)，有许多用于预测当前宏块的选项。首先，所有常用的预测选项都可用：在增强层分辨率下使用来自当前帧的样本的帧内模式，在增强层分辨率下使用来自先前编码和重构帧的样本的帧间预测。其次，一下进一步的选项可用，使用上采样较低层，图10.8中的基础层或下一个较低分辨率增强层作为参考层。请注意，当前MB位置对应于较低分辨率层中的较小块。下面的讨论假设在较低的参考层中有一个 8x8 的对应块，即所谓的并失标度，或者在增强层中有 2 * 水平和垂直分辨率。然而，H.264|SVC 支持任意层间缩放因子。

**预测选项：**  
1. 放到参考层。对于块内，将参考层缩放到当前层相同的分辨率(图10.8),并将参考层用作额外的预测参考。

注意，层间预测的约束条件如下。首先，可以用层间帧内预测进行编码的唯一增强层宏块是对其共定位参考样本进行帧内编码(约束帧内预测)的增强层宏块。第二，约束帧内预测对于更高层的层间预测是必须的。这意味着可以构造参考层中的帧内编码宏块，而不必重构任何帧间编码宏块。因此，可以使用单个运动补偿循环(单循环解读)对每一层进行解码，从而使得解码器的复杂度显著低于早期标准中的可伸缩视频编码。

2. 基本模式：使用参考图层块中的预测选项。

当基本模式标志设置为1时，在增强层中仅发送残差，没有额外的预测选择，即没有帧内预测模式或帧间分区、参考和运动向量。如果参考层中的共定位块以帧内模式编码，则使用 4 抽头有限脉冲响应滤波器对来自参考层的重构帧内块进行上采样，以产生对当前MB的预测。从MB中减去该预测以产生增强层残差。

如果参考层中的共定位块以帧间模式编码，则使用帧间预测来预测增强层块，其中(a)具有相同的参考图片索引,(b)从参考层中的分区向上采样的分区选择，(c)从参考层运动向量向上缩放的运动向量。

3. 参考层的运动矢量预测

如果运动预测标志设置为1，则使用帧间预测预测当前增强层宏块分区，其中(a)与相应参考层块相同的参考图片索引，(b)使用参考层的放大运动向量作为预测器创建的运动向量差(MVD)（第 6 章）。

4. 参考预测

当残差预测标志设置为1时，从参考层残差预测增强层残差。首先，使用双线性插值对参考层残差进行上采样，并从原始增强层块中减去该上采样残差。然后，使用上述任何方法，即传统帧内/帧间预测或基本模式预测，形成增强层残差。产生的差分信号像往常一样进行变换、编码和传输（第7章）。

### 10.2.9 质量缩放详解

H.264|SVC 支持粗粒度和中等粒度质量的可扩展性。粗粒度质量可伸缩性(CGS)实际上是空间可伸缩性的一种特殊情况，其中上采样/下采样因子为1。这意味着增强层分辨率与参考层分辨率相同(图10.7)。增强层以较低的QP编码，因此比较低的参考层具有更高的质量。上述所有“空间”可伸缩编码工具可用于从参考层重构真预测增强层帧。

质量可伸缩性的典型应用是提供以不同比特率和质量水平编码的序列的版本，以便，例如，可以提取较低比特率子序列以在具有不同容量的信道上传输。对于CGS，子序列比特率的数量受层数的限制。使用CGS提供大量比特率选项需要大量的层，这往往很复杂，编码效率也很低。

中等粒度质量可伸缩性（MGS）解决了这一限制，并使得从具有少量质量层的可伸缩比特流中以大范围比特率提取子流成为可能。使用MGS，可以丢弃增强层中的任何NAL单元以留下完全可解码的比特流。这使得产生各种输出比特率成为可能。例如，丢弃任意数量的增强层NAL单元可以在一定的误差范围内满足任意比特率目标。图10.9显示了一个示例。完整的可伸缩比特流由基本层NALU和增强层NALU组成，如图所示。使用MGS，可以丢弃所选择的增强层nalu以以逐渐降低的比特率提供子流。最低比特率/质量点由仅由基本层NALU组成的基本层流提供。SVC规定运动补偿预测参数不得在某些所谓关键图片的基本层和增强层表示之间更改。这防止了编码器和解码器处这些关键图片的运动补偿重建之间的“漂移”。因此，漂移仅限于非关键图片。

### 10.2.10 组合可伸缩性

H.264|SVC在可伸缩性比特流的构造中提供了相当大的灵活性，使得混合空间、时间和质量可伸缩性成为可能。例如，在图10.10中，在空间上对基本层进行上采样，并将上采样帧用作 B Slice 的参考，以产生具有空间和时间可伸缩性的层。然后，这用于预测具有相同时空分辨率但具有更高比特率和质量的另一层。

### 10.2.11 SVC 性能

对于需要在一定比特率范围内交付的给定序列，一个关键性能问题如下：可伸缩编码比同播编码提供的比特率更小还是更大？

MPEG技术报告N9577比较了SVC和AVC的性能。本报告描述了一系列测试，其中使用（a）AVC和（b）SVC对相同的视频剪辑进行编码。这些剪辑以不同的质量级别和分辨率进行编码。在每种情况下，都会产生一个低速率剪辑和一个高速率剪辑。低速率片段（a）使用AVC和（b）作为可伸缩流的基本层进行编码。高速率片段被编码为（a）单独的AVC流和（b）可伸缩流的增强层。选择操作比特率，使得解码序列的视觉质量在每个速率点（低和高）大致相同。每个剪辑的感知质量是通过结合一些观众的意见得分来衡量的（平均意见得分，见第2章）。

从中选择的结果如图10.12、图10.13和图10.14所示。图10.12对序列“Ofer”和“Paris”的两层质量可伸缩性进行了测试。低速率点表示以低比特率编码的30fps CIF序列。SVC基本层速率和主观质量（表示为“最高层的质量”）略高于AVC低速率流。速率上限点表示（a）两个AVC同播流或（b）两个SVC层的总比特率。请注意，x轴是累积比特率。显然，在这种情况下，SVC以较低的组合比特率实现与AVC相同的质量。如图10.11所示，两个同播流的总速率高于两个SVC层的总速率。

图10.13显示了组合空间和时间可伸缩性的类似结果。较低的速率点表示15fps，320×240视频，较高的速率点表示30fps，640×480视频，编码为（a）两个同步广播流或（b）基本和增强SVC层。同样，对于相同或更好的视觉质量，SVC层的组合速率低于AVC流的组合速率。有趣的是，“Crew”SVC基本层实际上被观众给予了非常高的质量分数。这可能是因为低分辨率序列（320×240×15fps）比高分辨率序列（640×480×30fps）具有更少的失真伪影，因此排列大致相同。

最后，图10.14显示了高清序列“Alohave”的结果，该序列具有空间可伸缩性或AVC同步广播，提供720p/50fps和1080p/50fps流。同样，SVC以比AVC更低的组合速率提供相同或更好的质量。请注意，主观质量似乎随着速率和分辨率的增加而下降。同样，这可能是由于更高分辨率序列中出现更明显的编码失真。

显示的结果表明，使用SVC以不同的速率、质量和分辨率交付序列的多个版本，即使相对温和，也有明显的好处。尽管自20世纪90年代初以来，可伸缩编码一直是一个活跃的研究课题，并已被纳入早期标准，如MPEG-2视频和MPEG-4视频，但它尚未被视频编码行业广泛采用，可能是因为成本和复杂性超过了技术优势。然而，有一些迹象表明，H.264 SVC是一个更具吸引力的商业提议，最近在视频会议市场上发布了产品。


## 10.3 多视点视频编码

多视图视频是包含特定场景的多个并发版本的视频数据。如图10.15所示；这三幅图像是从不同视角拍摄的同一真实世界场景的三个同时视图。多视图视频的潜在实现包括：

a. 立体视频。Astereo 对场景视图进行组合，例如，使用数据眼镜或自动立体显示器，尽管视角有限，但会产生三维视图的错觉(图10.16)。   
b. 3D 视频。通过使用"虚拟现实"眼镜或先进的自动立体显示器向观众呈现场景的多个实际视图或渲染视图，以便随着头部移动视图发生变化，观众在 3D 场景中有“沉浸”的感觉(图10.16)。  
c. 免费视点视频。有限数量的场景视图可用，例如，从体育比赛中的多个摄像头或多个监控摄像头。观看者可以选择任意视角。如果该视图不存在，则从可用的“真实”视图渲染或创建该视图（图10.16）  

多视点视频的应用包括3D电视、高级监控系统、沉浸式电话会议和游戏。  

与可伸缩视频类似，多视图视频内容具有固有的冗余，多视图视频编码（MVC）的目的是利用这种冗余并高效地编码多视图视频场景。图10.17显示了与多视图场景的一系列视图相对应的视频帧序列。每个视图由一系列帧或字段组成，这些帧或字段可编码为单独的H.264/AVC流，即每个视图的同播编码。但是，视图之间可能存在相关性，特别是当摄影机位置靠近时。因此，如果相机位置接近，则视图0的第0帧可能与视图1的第0帧强相关；视图1的帧0可与视图2的帧0相关；等等

### 10.3.1 多视点视频编码

多视图场景中的固有冗余可以通过在视图之间引入预测来利用，即视图间预测结构。这需要对H.264/AVC进行扩展，称为H.264多视图视频编码（H.264 MVC）。H.264多视点视频编码作为附录H并入H.264/AVC的修订草案中。有关参考软件，请访问。

如图10.18给出了多视角预测示例。使用传统 H.264|AVC 工具，使用分层 GOP 结构(第6章)预测视图0(顶部)。每个 GOP 由一个 I Slice 或关键图片和七个 B slice 组成。这意味着视图0可以由AVC或MVC解码器解码，并且可以被视为基本层或基本视图。其他每个视图都使用类似的预测结构，除了关键图片现在是P片，从上一个视图中的I或P片预测。视图间相关性意味着视图1、2、3中的P切片。可能比相同位置的I切片更有效地编码。

更复杂的预测结构包括每幅图片的采访预测（图10.19）。因此，视图1，2，3。将另一视图中的图片用作预测的参考。

H.264|AVC 的附录 H 规定了对基本 H.264 语法的一些补充，以支持 MVC，包括：

* 序列参数集：指定视图和锚定或关键图片引用。
* 参考图片列表：结构包括对视图间预测的支持。
* NAL单位顺序：修改为允许使用前缀NALU，其中包含有关基本视图的额外信息。该特殊前缀NAL单元可被不兼容MVC的AVC解码器丢弃，以便仍可解码基本视图。
* 图片编号和参考索引：修改为支持多个视图。

MVC必须面对与SVC相同的挑战，即与传统的多视图同时广播编码相比，MVC的优势值得额外的复杂性吗？多视点视频应用仍处于相对早期的阶段，目前还没有证据表明H.264 MVC作为一种编码技术将在业界流行。然而，像《阿凡达》这样的立体（“3D”）电影的流行正在引领制造商开发立体电视和蓝光解决方案。

## 10.4 可配置视频编码

H.264/AVC 是许多流行视频编码格式的较新补充，从早起标准 ITU-T 建议 H.261 和 ISO/IEC MPEG-1 开始，包括越来越多的标准和非标准格式。诸如 MPEG-2 视频、MEPG-4 视频、VC-1 和 H.264|AVC 等编码格式在当前的设备和系统中被广泛使用。这些格式或标准中没有一种是互操作的，即以一种格式编码的视频只能由支持相同格式的解码器解码。随着数字视频市场的持续增长，这给设备和编解码器制造商带来了越来越多的问题，因为他们需要支持多种不兼容的编码标准，从而导致过度设计的解码产品。有效支持多种编码格式的挑战已经引起了人们对可配置视频编码解决方案的兴趣。所有当前格式都有某些共同点，例如基于块的操作、帧间预测以及各种形式的变换和熵编码。找到一种利用这些共性的方法，可以高效灵活地支持多种视频编码格式。

可配置视频编解码器的一般概念如图10.20所示。在编码器侧，压缩视频使用视频编码器的特定配置(例如，使用标准或非标准编码格式)。配置信息和编码视频数据被发送到解码器。配置信息用于生成或配置视频解码算法。然后，所配置的视频解码器继续解压缩编码的视频序列。

可配置的编码系统有可能极大地提高视频编解码器的灵活性，使其能够重新配置编解码器以处理多种现有视频格式，或“升级”解码器以处理新的编码格式。设计此类系统的关键问题包括：

* 配置应该是完全灵活的，还是只限于一些预定义的选项？  
* 应该在何时进行配置？在通信会话开始时，通信会话期间或两者同时进行？  
* 可重新配置的编解码器能否实现与“硬连线”或固定软件或硬件编解码器相同的计算性能？
* 这种方法对现有编解码器的互操作性、视频流的随机访问以及编码算法的许可权等知识产权问题有何影响？

### 10.4.1 MPEG 可重构视频编码

MPEG的可重构视频编码(RVC)提案建立在十多年前最初提出的概念基础上，旨在“提供一个框架，允许动态开发、实施和采用具有更高灵活性和可重用性的标准化视频编码解决方案”。

MPEG的RVC子组开发了两个标准，可灵活地重新配置视频编解码器，从而可以高效地支持多种编码格式。在 RVC 模型中，解码器被指定为一组相互连接的功能单元(FU)，它们是解码工具，如逆变换和熵解码器。视频工具库(VTL)标准中指定了可用的FU。特定解码器由编解码器配置表示定义，其描述比特流格式和一组FU互连和参数。编解码器配置表示在开始解码会话之前指定。因此，RVC 视频解码器由一组预定义的解码工具构成。通过重新配置RVC解码器，可以支持现有或新的视频格式，前提是该格式使用视频工具库中的标准FUs。

图10.21 描述了一个典型的 RVC 解码场景。为了解码视频比特流，解码器需要知道(a)如何解析比特流并提取编码数据元素，(b)如何解码这些元素。RVC 解码引擎接收压缩形式的 BSDL 和 DDL 规范。解码器合成模块基于 BSDL 和 DDL 规范生成解码解决方案，即实际视频解码器。它使用视频工具库中选定的 FU，并根据 DDL 连接这些 FU。一旦生成解码解决方案，它就可以解码视频比特流。

MPEG RVC 方法有许多潜在的好处。通过发送新的 BSDL/DDL 描述，可以修改解码器以解码不同的格式，从而实现对多种编码格式的高效支持。可以支持非标准编码格式，前提是它使用解码器可用的FUs，即解码器VTL中的FUs。实际上，这意味着新格式应该使用MPEG标准化的FUs。可以向MPEG提出一种新的编码工具，作为一种新的FU进行标准化，这可能比创建一个完整的新视频编码标准更快、更简单。

为 RVC 模型特意选择的两个关键约束为：

1. 编码格式必须使用VTL中指定的编码工具（FU）组合。引入不在VTL中的新工具可能需要一个漫长的过程来标准化和传播VTL的新版本。
2. 解码器配置在通信会话的持续时间内是固定的，即，如果并且当视频序列的特征改变时，改变编码算法的可能性是有限的。

### 10.4.2 完全可配置编码

完全可配置视频编码(FCVC)已被提议作为 RVC 方法的替代或发展，FCVC 与 RVC 有两个不同之处。

1. 传输的配置信息完全描述了视频解码算法。这意味着(a)解码器不需要预定义视频编码工具库;(b)可以配置任何现有或新的视频编码算法。
2. 在视频通信会话期间的任何时候都可能发生重新配置。这使得能够动态地适应视频编码算法，例如基于视频序列的统计改变算法的方面。

在 FCVC 框架(图10.22)中，通用视频解码器(UVD)可以配置为对任何视频序列或语法进行解码。在典型应用中，UVD 最初对特定视频比特流所需的解码方法知之甚少或一无所知。编码器发送一组配置命令，即解码器描述语法（DDS），根据一组基本操作和互连定义解码器设计。UVD根据这些命令生成并连接新的功能处理单元，然后可以继续解码视频比特流。稍后，编码器可以通过发送新的解码器描述语法来表示配置的改变；UVD实现更改并使用更改的语法或功能继续解码比特流。与传统方法相比，FCVC具有以下优点：

i. 可以使用一组低级配置命令或用于描述解码操作的原语来定义和创建任何视频解码过程。新算法可以在很短的时间内在解码器中实现，这意味着很短的上市时间。    
ii. 可动态执行重新配置，实现动态自适应。这允许编解码器更改其配置以适应视频序列，从而提供最佳或接近最佳的压缩效率。  
iii. 单个通用视频解码器可以重新配置以支持任何现有或新的编码视频格式。  
iv. 通用视频解码器仅使用所需的工具进行编程。

最近的工作重点是开发和优化原型FCVC系统，并研究将FCVC和RVC结合起来的潜力。

## 10.5 超越 H.264|AVC

H.264|AVC 于 2003 年首次标准化，现在是一项相对成熟的技术。其他格式(如VC-1和AVS)可以提供类似的性能。但在编写本文时(2010年初)在压缩效率方面无疑是领先的格式之一。

运动图像专家组(MPEG)和视频编码专家组(VCEG)正在研究新的视频压缩标准的需求。在要求提供证据之后，在 2009 年 7月的一次 MPEG 会议上提出了几项改进视频压缩的建议。共识是：(a)随着消费者对更高质量视频的需求和处理能力的提高，可能需要一种新的压缩格式；(b)有可能提供比当前技术水平更好的性能。提出了许多不同的技术，包括解码器侧运动估计、较大的宏块大小(高达 32x32)、更复杂的环路内去块滤波器、自适应变换大小和改进的帧内预测。总的来说，所有这些算法都提供了更好的压缩性能，但计算复杂度有所增加。

通过新提案的主观比较测试结果，委员会得出结论：对于相当多的测试案例，可以实现 AVC High Profile 的显著收益。对于许多经过测试的视频序列，提出的新算法改善了 MOS 尺度上一个或多个点的主观质量(第 2 章)。这意味着有一种新的编码格式可以大大超过 H.264|AVC。

目前的计划是成立一个由 MPEG 和 VCEG 代表组成的联合协作小组(JCT),以指定新的视频编码标准。新标准的提案将在 2010 年进行审查，新标准可能在 2012/2013 年左右定稿。它的目标是提供比 H.264|AVC 更好的压缩性能，可能需要更高的计算成本。新标准的名称仍在讨论中。

## 10.6 结论

H.264|AVC 一直被认为是编码算法的工具包，可以扩展以满足未来的需求。最近的扩展包括可伸缩视频编码(SVC)和多视图视频编码(MVB)附近，它们建立在基本标准的基础上，增加了对多个相关视频流高效编码的支持。SVC 设计用于以不同的空间和时间分辨率以及不同的比特率容纳同一视频场景的多个版本，而MVC旨在处理场景的多个密切相关的视图。对于 SVC 和 MVC，都可以在增加复杂性的同时获得更好的压缩效率。尽管市场对 SVC 有一些兴趣，但这些扩展是否会被广泛采用还有待观察。

展望 H.264|AVC 之外，本章考虑的两个趋势是：(a)通过允许灵活地重新配置编码工具来"开放"视频编码；(b)开发一种新的、更高性能的标准，以提高压缩效率。这些趋势不一定是相互排斥的。随着视频内容变得越来越普遍，并给受限的网络连接带来前所未有的压力，可能会继续需要更好的压缩效率。与此同时，处理以多种格式编码的越来越多样化的内容的挑战使得可重构编码称为一个潜在的有用前景。














