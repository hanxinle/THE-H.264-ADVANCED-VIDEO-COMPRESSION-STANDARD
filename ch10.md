# 延伸和方向

## 10.1 引言

自 2003 年发布 H.264|AVC 的第一个版本依以来，视频编码行业一直在不断发展。视频平台和交付机制的范围不断扩大，人们越来越期望视频内容可以在任何平台上获得，从移动到高清和 3D 显示，通过任何网络，包括广播、互联网、移动等。自 2003 年以来，该标准本身已有所发展。本章总结了该标准最近的扩展，并介绍了 H.264 之后可能出现的情况。

所谓的“专业”或“保真度范围”扩展成为了 H.264 的High Profile，这是一种用于以极高的再现保真度对高清晰度和工作室内容进行编码的工具，如前几章所述。

越来越多的人需要以不同的带宽和显示分辨率对相同的原始内容进行编码，这导致了可伸缩视频编码(SVC)扩展到 H.264，标准化为 H.264 SVC。SVC 以这样的方式支持视频的有效编码，即视频信号的多个版本可以在比特率、空间分辨率和/或时间分辨率或帧速率的范围内解码。通过联合编码多个版本，应该能够以比单独编码和传输每个版本更有效的方式交付它们。

有一种趋势是创建和交付同一视频场景的多个视图。采用合适的显示技术的立体视频给人以三维(3D)图像的印象。场景的多个视图可以为用户提供选择其视点的选项。“自由视点”视频通过合成实际摄像机位置之间的中间视图，有可能提供场景的任何视图。这些“多视图”应用通常需要对多个密切相关的视频信号或视图进行编码。与SVC类似，多视图视频编码（MVC）利用这些视图之间的相关性来提供高效压缩。用于多视点视频编码的工具已经标准化为H.264 MVC。

视频压缩格式的数量不断增加，越来越多的内容被制作并编码成许多不同的、不兼容的压缩格式。可配置视频编码的最新举措解决了有效支持越来越多的压缩格式的问题。MPEG的可重构视频编码（RVC）子组定义了一个视频工具库、一组标准功能单元和视频压缩的构建块。可以通过定义功能单元的子集及其参数和互连来指定特定视频编解码器。这将使得灵活地重新配置视频编解码器以支持多种标准和专有格式称为可能。更进一步，完全可配置视频编码(FCVC)使得使用一组低级基本操作完全定义和实现任意视频编解码以及在视频通信会话期间更改该定义成为可能。这种方法的潜在好处包括能够快速实现任何新的视频编解码算法，并动态调整压缩算法以适应当前视频场景的特征。

H.264 已被证明是一种有用且成本的技术标准，并将继续增加其在视频编码市场中的份额。随着处理器能力的不断发展，标准界正在考虑 H.264/AVC 之后的内容。在撰写本文时(2010年初)，MPEG 和 VCEG 小组正在研究下一代视频编码标准的建议，该标准有望提供比 H.264 更好的性能，可能需要更高的计算成本。

## 10.2 可分级的视频编码基础

### 10.2.1 同播传输

许多视频压缩应用程序面临的一个挑战是在不同的操作点(即不同的质量、空间分辨率和帧速率)交付视频序列的多个版本。这可以通过使用传统视频编解码器(如H.264|AVC)通过独立地编码每个流来实现。这是联播。在典型的场景中(图10.1),需要将单个源视频传输到多个解码器或客户端，每个解码器或客户端具有不同的功能。在该示例中，原始视频剪辑被编码三次以上产生三个独立的AVC流，每个AVC流被发送和解码。同播场景的问题是三个比特流包含大量冗余，因为相同的视频序列以不同的分辨率和/或质量编码在每个比特流中。理论上，通过利用三个流之间的这种冗余，可以利用更小的传输带宽。

### 10.2.2 可伸缩传输

可伸缩视频编码(SVC)尝试交付多个视频序列的编码序列，它通过使用比上述同播场景更低的总体比特率来达到此目的。它通过利用不同版本之间的冗余来实现这一点，即在不同操作点编码额相同序列的不同版本之间的相关性。

如图10.2所示，使用SVC交付相同的三个序列。单个SVC编码器产生三个编码比特流，称为 Layers。最底层或基本层(图中的 Layer 0)是可使用标准单层解码器(例如，H.264 解码器)解码的流，以在可用质量/分辨率操作点中的最低质量/分辨率生成视频序列。一个或多个增强Layer(Layer 1 和 Layer 2)被编码为 SVC 比特流。为了以更高的质量或分辨率解码序列，SVC解码器解码基本层和一个或多个增强层。在该示例中，使用标准 AVC 解码器解码 Layer 0，产生最低质量的输出；使用SVC解码器解码 Layer 0 和 Layer 1产生更高质量的输出，使用SVC解码器解码 Layer0、Layer1和Layer2产生最高质量的输出。SVC 编码过程通过预测来自基本层和较低增强层的连续增强层，利用以不同分辨率或质量编码的序列之间的冗余。通过这种方式，应该能够以较低的贷款成本实现与同播系统(图10.1)相同的显示结果。

可伸缩编码比特流的一般概念是“流的一部分可以以这样的方式被移除，从而产生的子流形成用于某个目标解码器的另一个有效比特流”。考虑到图10.2，可伸缩比特流由编码的 Layer0、Layer1和Layer2流组成。解码所有三个流产生高质量的输出；移除 Layer2并解码Layer0和Layer1， 产生中等质量输出；移除 Layer1和Layer2并仅解码基本层会产生低质量的输出。

### 10.2.3 可伸缩视频编码的应用

可伸缩视频编码已经被提出用于许多应用场景。

**多解码器：** 越来越多地，相同的原始视频内容由多个设备编码、传输和观看，每个设备具有不同的功能。例如，电影预告片流式传输（从具有低比特率网络连接和低分辨率显示器的手持设备，到具有高比特率连接和高清晰度显示器的PC）到客户端。一系列因素可限制特定解码设备的能力，包括连接比特率、屏幕分辨率和处理能力。一个可伸缩的比特流应该能够尽可能有效地支持广泛的解码能力。

**优雅的降级/增强：** 虽然广播电视等一些应用往往具有清晰定义且一致的视频传输信道，但许多其他应用使用的信道在通信会话期间可能会发生较大的变换。例如，基于IP的应用程序(如视频流或internet会议)将经历不同的通道吞吐量，这取决于网络中的流量和拥塞等因素。可伸缩编码提供了一种机制，用于最大化特定解码器在特定时间点的质量。例如，流式服务器传输视频源的基本层和增强层。解码器尝试接收每个可用Layers。如果成功接收到所有 Layers，解码器将以最大可用质量提取序列。如果连接吞吐量下降，则解码器仅通过接收选定的Layers而回落到较低质量的序列。只要成功解码基本层，就可以始终显示基本质量的视频序列。这意味着基础层非常重要，即优先级高于增强层。

**Achieving** 将视频序列存储为可伸缩编码比特流可以使快速解码视频序列的低质量“预览”成为可能。例如，HD 序列被编码为多个可伸缩层。仅提取 Base Layer 会得到一个低质量的版本，该版本可以快速解码和显示，适合作为整个序列的预览。

### 10.2.4 H.264 中的可伸缩视频编码

可伸缩视频编码(SVC)作为H.264/AVC标准最新版本的附录G，并扩展了原始标准的功能。一个软件实现，联合可伸缩视频模型(JSVM)可供下载和实验。H.264 SVC 支持三种主要类型或类别的可伸缩性(如图10.3):

1. **时间可伸缩性：** Base Layer 是以低时间分辨率或低帧速率编码，添加增强层会增加解码序列的帧速率。    
2. **空间可伸缩性：** Base Layer 是以低空间分辨率编码，添加增强层可提高解码序列的空间分辨率。  
3. **质量可伸缩性：** Base Layer 使用高 QP 以低视觉质量编码；添加增强层可提高解码序列的视觉质量。  

## 10.3 多视点视频编码

多视图视频是包含特定场景的多个并发版本的视频数据。如图10.15所示；这三幅图像是从不同视角拍摄的同一真实世界场景的三个同时视图。多视图视频的潜在实现包括：

a. 立体视频。Astereo 对场景视图进行组合，例如，使用数据眼镜或自动立体显示器，尽管视角有限，但会产生三维视图的错觉(图10.16)。   
b. 3D 视频。通过使用"虚拟现实"眼镜或先进的自动立体显示器向观众呈现场景的多个实际视图或渲染视图，以便随着头部移动视图发生变化，观众在 3D 场景中有“沉浸”的感觉(图10.16)。  
c. 免费视点视频。有限数量的场景视图可用，例如，从体育比赛中的多个摄像头或多个监控摄像头。观看者可以选择任意视角。如果该视图不存在，则从可用的“真实”视图渲染或创建该视图（图10.16）  

多视点视频的应用包括3D电视、高级监控系统、沉浸式电话会议和游戏。  

与可伸缩视频类似，多视图视频内容具有固有的冗余，多视图视频编码（MVC）的目的是利用这种冗余并高效地编码多视图视频场景。图10.17显示了与多视图场景的一系列视图相对应的视频帧序列。每个视图由一系列帧或字段组成，这些帧或字段可编码为单独的H.264/AVC流，即每个视图的同播编码。但是，视图之间可能存在相关性，特别是当摄影机位置靠近时。因此，如果相机位置接近，则视图0的第0帧可能与视图1的第0帧强相关；视图1的帧0可与视图2的帧0相关；等等

### 10.3.1 多视点视频编码

多视图场景中的固有冗余可以通过在视图之间引入预测来利用，即视图间预测结构。这需要对H.264/AVC进行扩展，称为H.264多视图视频编码（H.264 MVC）。H.264多视点视频编码作为附录H并入H.264/AVC的修订草案中。有关参考软件，请访问。

如图10.18给出了多视角预测示例。使用传统 H.264|AVC 工具，使用分层 GOP 结构(第6章)预测视图0(顶部)。每个 GOP 由一个 I Slice 或关键图片和七个 B slice 组成。这意味着视图0可以由AVC或MVC解码器解码，并且可以被视为基本层或基本视图。其他每个视图都使用类似的预测结构，除了关键图片现在是P片，从上一个视图中的I或P片预测。视图间相关性意味着视图1、2、3中的P切片。可能比相同位置的I切片更有效地编码。

更复杂的预测结构包括每幅图片的采访预测（图10.19）。因此，视图1，2，3。将另一视图中的图片用作预测的参考。

H.264|AVC 的附录 H 规定了对基本 H.264 语法的一些补充，以支持 MVC，包括：

* 序列参数集：指定视图和锚定或关键图片引用。
* 参考图片列表：结构包括对视图间预测的支持。
* NAL单位顺序：修改为允许使用前缀NALU，其中包含有关基本视图的额外信息。该特殊前缀NAL单元可被不兼容MVC的AVC解码器丢弃，以便仍可解码基本视图。
* 图片编号和参考索引：修改为支持多个视图。

MVC必须面对与SVC相同的挑战，即与传统的多视图同时广播编码相比，MVC的优势值得额外的复杂性吗？多视点视频应用仍处于相对早期的阶段，目前还没有证据表明H.264 MVC作为一种编码技术将在业界流行。然而，像《阿凡达》这样的立体（“3D”）电影的流行正在引领制造商开发立体电视和蓝光解决方案。

## 10.4 可配置视频编码

H.264/AVC 是许多流行视频编码格式的较新补充，从早起标准 ITU-T 建议 H.261 和 ISO/IEC MPEG-1 开始，包括越来越多的标准和非标准格式。诸如 MPEG-2 视频、MEPG-4 视频、VC-1 和 H.264|AVC 等编码格式在当前的设备和系统中被广泛使用。这些格式或标准中没有一种是互操作的，即以一种格式编码的视频只能由支持相同格式的解码器解码。随着数字视频市场的持续增长，这给设备和编解码器制造商带来了越来越多的问题，因为他们需要支持多种不兼容的编码标准，从而导致过度设计的解码产品。有效支持多种编码格式的挑战已经引起了人们对可配置视频编码解决方案的兴趣。所有当前格式都有某些共同点，例如基于块的操作、帧间预测以及各种形式的变换和熵编码。找到一种利用这些共性的方法，可以高效灵活地支持多种视频编码格式。

可配置视频编解码器的一般概念如图10.20所示。在编码器侧，压缩视频使用视频编码器的特定配置(例如，使用标准或非标准编码格式)。配置信息和编码视频数据被发送到解码器。配置信息用于生成或配置视频解码算法。然后，所配置的视频解码器继续解压缩编码的视频序列。

可配置的编码系统有可能极大地提高视频编解码器的灵活性，使其能够重新配置编解码器以处理多种现有视频格式，或“升级”解码器以处理新的编码格式。设计此类系统的关键问题包括：

* 配置应该是完全灵活的，还是只限于一些预定义的选项？  
* 应该在何时进行配置？在通信会话开始时，通信会话期间或两者同时进行？  
* 可重新配置的编解码器能否实现与“硬连线”或固定软件或硬件编解码器相同的计算性能？
* 这种方法对现有编解码器的互操作性、视频流的随机访问以及编码算法的许可权等知识产权问题有何影响？

### 10.4.1 MPEG 可重构视频编码

MPEG的可重构视频编码(RVC)提案建立在十多年前最初提出的概念基础上，旨在“提供一个框架，允许动态开发、实施和采用具有更高灵活性和可重用性的标准化视频编码解决方案”。

MPEG的RVC子组开发了两个标准，可灵活地重新配置视频编解码器，从而可以高效地支持多种编码格式。在 RVC 模型中，解码器被指定为一组相互连接的功能单元(FU)，它们是解码工具，如逆变换和熵解码器。视频工具库(VTL)标准中指定了可用的FU。特定解码器由编解码器配置表示定义，其描述比特流格式和一组FU互连和参数。编解码器配置表示在开始解码会话之前指定。因此，RVC 视频解码器由一组预定义的解码工具构成。通过重新配置RVC解码器，可以支持现有或新的视频格式，前提是该格式使用视频工具库中的标准FUs。

图10.21 描述了一个典型的 RVC 解码场景。为了解码视频比特流，解码器需要知道(a)如何解析比特流并提取编码数据元素，(b)如何解码这些元素。RVC 解码引擎接收压缩形式的 BSDL 和 DDL 规范。解码器合成模块基于 BSDL 和 DDL 规范生成解码解决方案，即实际视频解码器。它使用视频工具库中选定的 FU，并根据 DDL 连接这些 FU。一旦生成解码解决方案，它就可以解码视频比特流。

MPEG RVC 方法有许多潜在的好处。通过发送新的 BSDL/DDL 描述，可以修改解码器以解码不同的格式，从而实现对多种编码格式的高效支持。可以支持非标准编码格式，前提是它使用解码器可用的FUs，即解码器VTL中的FUs。实际上，这意味着新格式应该使用MPEG标准化的FUs。可以向MPEG提出一种新的编码工具，作为一种新的FU进行标准化，这可能比创建一个完整的新视频编码标准更快、更简单。

为 RVC 模型特意选择的两个关键约束为：

1. 编码格式必须使用VTL中指定的编码工具（FU）组合。引入不在VTL中的新工具可能需要一个漫长的过程来标准化和传播VTL的新版本。
2. 解码器配置在通信会话的持续时间内是固定的，即，如果并且当视频序列的特征改变时，改变编码算法的可能性是有限的。

### 10.4.2 完全可配置编码

完全可配置视频编码(FCVC)已被提议作为 RVC 方法的替代或发展，FCVC 与 RVC 有两个不同之处。

1. 传输的配置信息完全描述了视频解码算法。这意味着(a)解码器不需要预定义视频编码工具库;(b)可以配置任何现有或新的视频编码算法。
2. 在视频通信会话期间的任何时候都可能发生重新配置。这使得能够动态地适应视频编码算法，例如基于视频序列的统计改变算法的方面。

在 FCVC 框架(图10.22)中，通用视频解码器(UVD)可以配置为对任何视频序列或语法进行解码。在典型应用中，UVD 最初对特定视频比特流所需的解码方法知之甚少或一无所知。编码器发送一组配置命令，即解码器描述语法（DDS），根据一组基本操作和互连定义解码器设计。UVD根据这些命令生成并连接新的功能处理单元，然后可以继续解码视频比特流。稍后，编码器可以通过发送新的解码器描述语法来表示配置的改变；UVD实现更改并使用更改的语法或功能继续解码比特流。与传统方法相比，FCVC具有以下优点：

i. 可以使用一组低级配置命令或用于描述解码操作的原语来定义和创建任何视频解码过程。新算法可以在很短的时间内在解码器中实现，这意味着很短的上市时间。    
ii. 可动态执行重新配置，实现动态自适应。这允许编解码器更改其配置以适应视频序列，从而提供最佳或接近最佳的压缩效率。  
iii. 单个通用视频解码器可以重新配置以支持任何现有或新的编码视频格式。  
iv. 通用视频解码器仅使用所需的工具进行编程。

最近的工作重点是开发和优化原型FCVC系统，并研究将FCVC和RVC结合起来的潜力。

## 10.5 超越 H.264|AVC

H.264|AVC 于 2003 年首次标准化，现在是一项相对成熟的技术。其他格式(如VC-1和AVS)可以提供类似的性能。但在编写本文时(2010年初)在压缩效率方面无疑是领先的格式之一。

运动图像专家组(MPEG)和视频编码专家组(VCEG)正在研究新的视频压缩标准的需求。在要求提供证据之后，在 2009 年 7月的一次 MPEG 会议上提出了几项改进视频压缩的建议。共识是：(a)随着消费者对更高质量视频的需求和处理能力的提高，可能需要一种新的压缩格式；(b)有可能提供比当前技术水平更好的性能。提出了许多不同的技术，包括解码器侧运动估计、较大的宏块大小(高达 32x32)、更复杂的环路内去块滤波器、自适应变换大小和改进的帧内预测。总的来说，所有这些算法都提供了更好的压缩性能，但计算复杂度有所增加。

通过新提案的主观比较测试结果，委员会得出结论：对于相当多的测试案例，可以实现 AVC High Profile 的显著收益。对于许多经过测试的视频序列，提出的新算法改善了 MOS 尺度上一个或多个点的主观质量(第 2 章)。这意味着有一种新的编码格式可以大大超过 H.264|AVC。

目前的计划是成立一个由 MPEG 和 VCEG 代表组成的联合协作小组(JCT),以指定新的视频编码标准。新标准的提案将在 2010 年进行审查，新标准可能在 2012/2013 年左右定稿。它的目标是提供比 H.264|AVC 更好的压缩性能，可能需要更高的计算成本。新标准的名称仍在讨论中。

## 10.6 结论

H.264|AVC 一直被认为是编码算法的工具包，可以扩展以满足未来的需求。最近的扩展包括可伸缩视频编码(SVC)和多视图视频编码(MVB)附近，它们建立在基本标准的基础上，增加了对多个相关视频流高效编码的支持。SVC 设计用于以不同的空间和时间分辨率以及不同的比特率容纳同一视频场景的多个版本，而MVC旨在处理场景的多个密切相关的视图。对于 SVC 和 MVC，都可以在增加复杂性的同时获得更好的压缩效率。尽管市场对 SVC 有一些兴趣，但这些扩展是否会被广泛采用还有待观察。

展望 H.264|AVC 之外，本章考虑的两个趋势是：(a)通过允许灵活地重新配置编码工具来"开放"视频编码；(b)开发一种新的、更高性能的标准，以提高压缩效率。这些趋势不一定是相互排斥的。随着视频内容变得越来越普遍，并给受限的网络连接带来前所未有的压力，可能会继续需要更好的压缩效率。与此同时，处理以多种格式编码的越来越多样化的内容的挑战使得可重构编码称为一个潜在的有用前景。














